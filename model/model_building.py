# -*- coding: utf-8 -*-
"""model_building.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V8V-7RfQoDpGXFu3oAuIBpUyQMjrOzKY
"""

import os
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# ------------------------------
# 1. Load dataset
# ------------------------------
# Make sure titanic.csv is in the SAME folder as this file
data_path = "titanic.csv"
df = pd.read_csv(data_path)

print("Dataset shape:", df.shape)
print("Columns:", df.columns.tolist())

# ------------------------------
# 2. Feature selection
# ------------------------------
feature_cols = ["Pclass", "Sex", "Age", "SibSp", "Embarked"]  # 5 features
target_col = "Survived"

X = df[feature_cols]
y = df[target_col]

print("\nSelected features:", feature_cols)
print("X shape:", X.shape)
print("y shape:", y.shape)

# ------------------------------
# 3. Train-test split
# ------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("\nTrain size:", X_train.shape[0])
print("Test size:", X_test.shape[0])

# ------------------------------
# 4. Preprocessing
# ------------------------------
numeric_features = ["Age", "SibSp", "Pclass"]
categorical_features = ["Sex", "Embarked"]

numeric_transformer = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="median")),   # handle missing Age, etc
        ("scaler", StandardScaler()),                    # feature scaling
    ]
)

categorical_transformer = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),  # handle missing Embarked
        ("onehot", OneHotEncoder(handle_unknown="ignore")),    # encode Sex, Embarked
    ]
)

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features),
    ]
)

# ------------------------------
# 5. Model – Logistic Regression
# ------------------------------
clf = LogisticRegression(max_iter=1000)

model = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", clf),
    ]
)

# ------------------------------
# 6. Train the model
# ------------------------------
model.fit(X_train, y_train)

# ------------------------------
# 7. Evaluate – classification report
# ------------------------------
y_pred = model.predict(X_test)
print("\n=== Classification Report ===")
print(classification_report(y_test, y_pred, digits=4))

# ------------------------------
# 8. Save trained model to disk
# ------------------------------
os.makedirs("model", exist_ok=True)
model_path = os.path.join("model", "titanic_survival_model.pkl")

# Save both the model pipeline and the feature list
joblib.dump(
    {"model": model, "features": feature_cols},
    model_path
)

print(f"\nModel saved successfully to: {model_path}")

# ------------------------------
# 9. Demonstrate reload & predict
# ------------------------------
loaded_data = joblib.load(model_path)
loaded_model = loaded_data["model"]
loaded_features = loaded_data["features"]

print("\nLoaded features from file:", loaded_features)

example = X_test.iloc[[0]]   # single row as a DataFrame
true_label = y_test.iloc[0]
pred_label = loaded_model.predict(example)[0]

print("\n=== Reloaded Model Prediction Demo ===")
print("Example passenger features:")
print(example)
print(f"True label: {true_label} (0 = Did Not Survive, 1 = Survived)")
print(f"Predicted label by loaded model: {pred_label}")